{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing parsing of various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd \n",
    "import json \n",
    "\n",
    "\n",
    "# add parse function \n",
    "xPath_package = '/home/mike/PycharmProjects/grant_db/'\n",
    "sys.path.append(xPath_package)\n",
    "\n",
    "# connection strings \n",
    "#xPGConnString = 'postgresql://postgres:post@localhost:5432/eris'\n",
    "#xDBCon = create_engine(xPGConnString)\n",
    "\n",
    "xDB = '/media/mike/MyDataContainer/1000_ScientoMetricData/___Staging/1000_GRANTS/2000_dset_parsed/grant_dset.db'\n",
    "xDBCon = 'sqlite:///' + xDB \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTR PARSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from etl import etl_parse_gtr as GTR_PAR\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# projects \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persons files: 3280\n",
      "persons records: 65600\n"
     ]
    }
   ],
   "source": [
    "# parse person \n",
    "xFld_GTR = '/media/mike/MyDataContainer/1000_ScientoMetricData/___Staging/1000_GRANTS/1000_dset_original/8000_GatewayResearch/'\n",
    "xFld_GTR_Data = xFld_GTR  + '300_persons/'\n",
    "xlst_data = os.listdir(xFld_GTR_Data)\n",
    "print 'persons files:', len(xlst_data)\n",
    "\n",
    "xlst_dict_persons = []\n",
    "\n",
    "for xFileData in xlst_data:\n",
    "    xFileName = xFld_GTR_Data +xFileData\n",
    "    \n",
    "    xlst_dict_persons = xlst_dict_persons + GTR_PAR.gtr_parse_person(xFileName)\n",
    "    \n",
    "print 'persons records:', len(xlst_dict_persons)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_df1 = pd.DataFrame(xlst_dict_persons[0:6])\n",
    "\n",
    "x_df1.to_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parse person \n",
    "xFld_GTR = '/media/mike/MyDataContainer/1000_ScientoMetricData/___Staging/1000_GRANTS/1000_dset_original/8000_GatewayResearch/'\n",
    "xFld_GTR_persons = xFld_GTR  + '300_persons/'\n",
    "xlst_pers = os.listdir(xFld_GTR_persons)\n",
    "len(xlst_pers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gtr_parse_person(xFile):\n",
    "    '''\n",
    "    parse Files for Person\n",
    "    return : a list of dictionary with  \n",
    "    id and names \n",
    "    '''\n",
    "    xres_list_persons = []\n",
    "\n",
    "    with open(xFile, 'r') as ff:\n",
    "        xData = ff.read()\n",
    "    xDataJson = json.loads(xData)\n",
    "    xlst_persons = xDataJson['person']\n",
    "    \n",
    "    for x_person in xlst_persons:\n",
    "        xDictRes = dict.fromkeys(['person_id', \n",
    "                                  'person_name_last',\n",
    "                                  'person_name_first',\n",
    "                                  'person_name_others'])\n",
    "\n",
    "        xDictRes['person_id']        = x_person['id']\n",
    "        xDictRes['person_name_last'] = x_person['surname']\n",
    "        xDictRes['person_name_first'] = x_person['firstName']\n",
    "        xDictRes['person_name_others'] = x_person['otherNames']\n",
    "\n",
    "        xres_list_persons.append(xDictRes)\n",
    "    return xres_list_persons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xFile = xFld_GTR_persons + xlst_pers[89]\n",
    "\n",
    "xres_list_persons = []\n",
    "   \n",
    "with open(xFile, 'r') as ff:\n",
    "    xData = ff.read()\n",
    "xDataJson = json.loads(xData)\n",
    "xlst_persons = xDataJson['person']\n",
    "x_person = xlst_persons[4]\n",
    "\n",
    "xDictRes = dict.fromkeys(['person_id', \n",
    "                          'person_name_last',\n",
    "                          'person_name_first',\n",
    "                          'person_name_others'\n",
    "                         ])\n",
    "\n",
    "xDictRes['person_id']        = x_person['id']\n",
    "xDictRes['person_name_last'] = x_person['surname']\n",
    "xDictRes['person_name_first'] = x_person['firstName']\n",
    "xDictRes['person_name_others'] = x_person['otherNames']\n",
    "\n",
    "xDictRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gtr_parse_org(xFile):\n",
    "    '''\n",
    "    parse Files for Organisations \n",
    "    return : a list of dictionary with  \n",
    "    org_id and org_name and main adress county and town \n",
    "    '''\n",
    "    \n",
    "    xres_list_orgs = []\n",
    "    \n",
    "    with open(xFile, 'r') as ff:\n",
    "        xData = ff.read()\n",
    "    xDataJson = json.loads(xData)\n",
    "    \n",
    "    xlst_orgs =xDataJson['organisation']\n",
    "\n",
    "    for x_org in xlst_orgs:\n",
    "        xDictRes = dict.fromkeys(['org_id', 'org_name',\n",
    "                                  'address_main_county', 'address_main_region', \n",
    "                                  'address_main_postcode', 'address_main_line1'])\n",
    "\n",
    "        xDictRes['org_id'] = x_org['id']\n",
    "        xDictRes['org_name'] = x_org['name'] \n",
    "\n",
    "        if x_org.has_key('addresses') and (x_org['addresses']).has_key('address'):\n",
    "            xlst_addresses = x_org['addresses']['address']\n",
    "            for x_address in xlst_addresses:\n",
    "                if x_address['type'] == 'MAIN_ADDRESS':\n",
    "                    if x_address.has_key('county'):\n",
    "                        xDictRes['address_main_county'] = x_address['county']  \n",
    "                    if x_address.has_key('region'):\n",
    "                        xDictRes['address_main_region'] = x_address['region']  \n",
    "                    if x_address.has_key('postCode'):\n",
    "                        xDictRes['address_main_postcode'] = x_address['postCode'] \n",
    "                    if x_address.has_key('line1'):\n",
    "                        xDictRes['address_main_line1'] = x_address['line1'] \n",
    "        \n",
    "        xres_list_orgs.append(xDictRes)\n",
    "        \n",
    "        \n",
    "    return xres_list_orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xFileName = xFld_GTR_org + xlst_org[0]\n",
    "xFileName\n",
    "gtr_parse_org(xFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(xFileName, 'r') as ff:\n",
    "    xData = ff.read()\n",
    "xDataJson = json.loads(xData)\n",
    "\n",
    "for x_org in xlst_orgs:\n",
    "    xDictRes = dict.fromkeys(['org_id', 'org_name',\n",
    "                              'address_main_county', 'address_main_region', \n",
    "                              'address_main_postcode', 'address_main_line1'])\n",
    "        \n",
    "    xDictRes['org_id'] = x_org['id']\n",
    "    xDictRes['org_name'] = x_org['name'] \n",
    "    \n",
    "    if x_org.has_key('addresses') and (x_org['addresses']).has_key('address'):\n",
    "        xlst_addresses = x_org['addresses']['address']\n",
    "        for x_address in xlst_addresses:\n",
    "            if x_address['type'] == 'MAIN_ADDRESS':\n",
    "                if x_address.has_key('county'):\n",
    "                    xDictRes['address_main_county'] = x_address['county']  \n",
    "                if x_address.has_key('region'):\n",
    "                    xDictRes['address_main_region'] = x_address['region']  \n",
    "                if x_address.has_key('postCode'):\n",
    "                    xDictRes['address_main_postcode'] = x_address['postCode'] \n",
    "                if x_address.has_key('line1'):\n",
    "                    xDictRes['address_main_line1'] = x_address['line1'] \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xlst_addresses = x_org['addresses']['address']\n",
    "for x_address in xlst_addresses:\n",
    "    if x_address['type'] == 'MAIN_ADDRESS':\n",
    "        xDictRes['adress_main_county'] = x_address['county']  \n",
    "        xDictRes['adress_main_region'] = x_address['region']  \n",
    "        xDictRes['adress_main_postcode'] = x_address['postCode']          \n",
    "xDictRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xFile = xFld_GTR_org + xlst_org[0]\n",
    "xFile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xDataJson.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gtr_parse_projects(xFile):\n",
    "    '''\n",
    "    #parse project data from Gateway to research\n",
    "    RETURN: \n",
    "    return a dictionary with project data (list) and a list of \"relations\"\n",
    "    #N.B: metadata on relations such as PI, Funding Organisation or Performing Organisation\n",
    "    # should be fetched separately\n",
    "    #for example given their IDs\n",
    "    \n",
    "    '''\n",
    "\n",
    "    xDictRes = {}\n",
    "    \n",
    "    xlst_links_res = []  # results links\n",
    "    xlst_projectData = []\n",
    "\n",
    "    with open(xFile, 'r') as ff:\n",
    "        xData = ff.read()\n",
    "    xDataJson = json.loads(xData)\n",
    "    xlst_projects = xDataJson['project']\n",
    "\n",
    "    xFields_project = ['id',\n",
    "                       'created',\n",
    "                       'href',\n",
    "                       'status',\n",
    "                       'title',\n",
    "                       'grantCategory',\n",
    "                       'abstractText',\n",
    "                       'potentialImpact',\n",
    "                       'identifiers',\n",
    "                       'researchTopics',\n",
    "                       'researchSubjects',\n",
    "                       'healthCategories',\n",
    "                       'researchActivities',\n",
    "                       'leadOrganisationDepartment'\n",
    "                       ]\n",
    "\n",
    "\n",
    "    for x_project in xlst_projects:\n",
    "        \n",
    "        # links\n",
    "        xFields_links = ['id', 'href', 'rel']\n",
    "\n",
    "        x_data_project = dict.fromkeys(xFields_project)\n",
    "        x_data_project['id'] = x_project['id']\n",
    "        x_data_project['created'] = x_project['created']\n",
    "\n",
    "        x_data_project['href'] = x_project['href']\n",
    "        x_data_project['status'] = x_project['status']\n",
    "        x_data_project['title'] = x_project['title']\n",
    "        x_data_project['grantCategory'] = x_project['grantCategory']\n",
    "\n",
    "        x_data_project['abstractText'] = x_project['abstractText']\n",
    "\n",
    "        if x_project.has_key('potentialImpact'):\n",
    "            x_data_project['potentialImpact'] = x_project['potentialImpact']\n",
    "\n",
    "        if x_project.has_key('identifiers'):\n",
    "            lst_identifiers = x_project['identifiers']['identifier']\n",
    "            x_data_project['identifiers'] = ';'.join([x['type'] + '_' + x['value'] for x in lst_identifiers])\n",
    "\n",
    "        if x_project.has_key('researchTopics'):\n",
    "            xlst_research_topics = x_project['researchTopics']['researchTopic']\n",
    "            x_data_project['researchTopics'] = ';'.join([x['id'] + '_' + x['text'] for x in xlst_research_topics])\n",
    "\n",
    "        if x_project.has_key('researchSubjects'):\n",
    "            xlst_research_topics = x_project['researchSubjects']['researchSubject']\n",
    "            x_data_project['researchSubjects'] = ';'.join([x['id'] + '_' + x['text'] for x in xlst_research_topics])\n",
    "\n",
    "        if x_project.has_key('healthCategories'):\n",
    "            xlst_research_topics = x_project['healthCategories']['healthCategory']\n",
    "            x_data_project['healthCategories'] = ';'.join([x['id'] + '_' + x['text'] for x in xlst_research_topics])\n",
    "\n",
    "        if x_project.has_key('researchActivities'):\n",
    "            xlst_research_topics = x_project['researchActivities']['researchActivity']\n",
    "            x_data_project['researchActivities'] = ';'.join([x['id'] + '_' + x['text'] for x in xlst_research_topics])\n",
    "\n",
    "        if x_project.has_key('leadOrganisationDepartment'):\n",
    "            x_data_project['leadOrganisationDepartment'] = x_project['leadOrganisationDepartment']\n",
    "\n",
    "        xlst_projectData.append(x_data_project)    \n",
    "        \n",
    "        # process links\n",
    "        xlst_links = x_project['links']['link']\n",
    "\n",
    "        for xDict in xlst_links:\n",
    "            xDictLink = dict.fromkeys(xFields_links)\n",
    "            xDictLink['id'] = x_project['id']\n",
    "            xDictLink['href'] = xDict['href']\n",
    "            xDictLink['rel'] = xDict['rel']\n",
    "            xlst_links_res.append(xDictLink)\n",
    "\n",
    "    xDictRes['grant_data']  = xlst_projectData\n",
    "    xDictRes['grant_links'] = xlst_links_res\n",
    "\n",
    "\n",
    "    return xDictRes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtr_parse_projects(xFile)['grant_data'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtr_parse_projects(xFile)['grant_links'][1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from etl import etl_parse_nsf as p_nsf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xFld = '/media/mike/MyDataContainer/1000_ScientoMetricData/___Staging/1000_GRANTS/1000_dset_original/5000_NSF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '! starting', time.ctime()\n",
    "\n",
    "for x_year in range(2000, 2017):\n",
    "    x_year_str = str(x_year)\n",
    "    xFile_Zipped = xFld + x_year_str + '.zip'\n",
    "    print '--process', x_year_str\n",
    "    \n",
    "    xq1 = p_nsf.parse_nsf_grant_to_csv(xFile_Zipped)\n",
    "    \n",
    "    for xkey in xq1.keys():\n",
    "        xTabName = 'nsf_' + x_year_str + '_' + xkey\n",
    "    \n",
    "        (xq1[xkey]).to_sql(name = xTabName,\n",
    "                           con = xDBCon, \n",
    "                           if_exists='replace', \n",
    "                           index=True, index_label='record_id', \n",
    "                           chunksize=10000)\n",
    "        print '------saved',  xTabName, 'records:', len(xq1[xkey]), time.ctime()\n",
    "    \n",
    "    \n",
    "    \n",
    "print '-- all done' , time.ctime()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xFld = '/media/mike/MyDataContainer/1000_ScientoMetricData/___Staging/1000_GRANTS/1000_dset_original/4000_NIH/_CSV/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT THE TABLES -- projects \n",
    "print '--- starting', time.ctime()\n",
    "for x_year in range(2006, 2017):\n",
    "    x_year_str = str(x_year)\n",
    "    print '-------------------- process: ', x_year_str\n",
    "    xFile_Zipped = xFld + x_year_str + '.zip'\n",
    "    xFile_nonZipped = 'RePORTER_PRJ_C_FY' + x_year_str + '.csv'\n",
    "    xTabName = 'nih_' + x_year_str + 'projects' \n",
    "    \n",
    "    #Process File \n",
    "    df1 = None\n",
    "    with zipfile.ZipFile(xFile_Zipped ) as z:\n",
    "        with z.open(xFile_nonZipped) as f:\n",
    "            df1 = pd.read_csv(f, low_memory=False, encoding='latin-1')#, nrows=100)\n",
    "            #print len(df1)\n",
    "            \n",
    "            df1.to_sql(name = xTabName, \n",
    "                       con = xDBCon, \n",
    "                       if_exists='replace', \n",
    "                       index=True, index_label='record_id', \n",
    "                       chunksize=10000)\n",
    "    \n",
    "            print 'saved ! records:', len(df1) ,  time.ctime()\n",
    "    \n",
    "print '--------all done---' , time.ctime()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# abstracts \n",
    "\n",
    "print '--- starting', time.ctime()\n",
    "for x_year in range(2006, 2017):\n",
    "    x_year_str = str(x_year)\n",
    "    print '-------------------- process: ', x_year_str\n",
    "    xFile_Zipped = xFld + x_year_str + '_abstract.zip'\n",
    "    xFile_nonZipped = 'RePORTER_PRJABS_C_FY' + x_year_str + '.csv'\n",
    "    xTabName = 'nih_' + x_year_str + 'projects_abst' \n",
    "    \n",
    "    \n",
    "    #Process File \n",
    "    df1 = None\n",
    "    with zipfile.ZipFile(xFile_Zipped ) as z:\n",
    "        with z.open(xFile_nonZipped) as f:\n",
    "            df1 = pd.read_csv(f, low_memory=False, encoding='latin-1')#, nrows=100)\n",
    "            #print len(df1)\n",
    "            \n",
    "            df1.to_sql(name = xTabName, \n",
    "                       con = xDBCon, \n",
    "                       if_exists='replace', \n",
    "                       index=True, index_label='record_id', \n",
    "                       chunksize=10000)\n",
    "    \n",
    "            print 'saved ! records:', len(df1) ,  time.ctime()\n",
    "    \n",
    "print '--------all done---' , time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
